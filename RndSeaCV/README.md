# Web Scraping and Classification

For this project I have used following third-party packages: 
* NumPy, 
* Pandas,
* BeautifulSoup (bs4),
* urllib.requests.
# News Scraping For BBC

This project focuses on scraping news articles from a public news website of your choice wherein this case i have used BBC website which has its terms and conditions applied. The script collects approximately 100 news articles and categorizes them using the website's predefined classifications (e.g., sections like politics, business, technology). The primary goal is to assess the effectiveness of a text classification model in correctly categorizing news articles.

## Table of Contents

Key Features
Website Agnostic Scraping: The scraping script is designed to work with any news website URL that contains articles, providing flexibility for different sources.

Replicable Setup: The project includes a setup that can be easily replicated on other machines, ensuring consistency for testing and code deployment.

Data Storage: Scraped data is stored in a dedicated folder along with the script, promoting organization and easy access to the collected articles.

Text Classification Model: Utilizes a text classification model of your choice to classify news articles based on predefined sections.

Evaluation Report: Generates a CSV/Excel report summarizing the model's accuracy and performance on the test dataset

## Instructions

Clone the Repository:
``` git clone https://github.com/Samxnx/NewsScraping.git ```
```cd NewsScraping ```

